{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "referenced-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from stargazer.stargazer import Stargazer\n",
    "from functools import reduce\n",
    "from IPython.core.display import HTML\n",
    "import webbrowser\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "geographic-emphasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open all correct dataframes\n",
    "btc_1d = pd.read_csv('BFX-BTCUSD-1d.csv', usecols=['timestamp', 'open', 'close', 'high', 'low', 'volume'])\n",
    "btc_1h = pd.read_csv('BFX-BTCUSD-1h.csv', usecols=['timestamp', 'open', 'close', 'high', 'low', 'volume'])\n",
    "btc_15m = pd.read_csv('BFX-BTCUSD-15m.csv', usecols=['timestamp', 'open', 'close', 'high', 'low', 'volume'])\n",
    "btc_1m = pd.read_csv('BFX-BTCUSD-1m.csv', usecols=['timestamp', 'open', 'close', 'high', 'low', 'volume'])\n",
    "\n",
    "usdt_1d = pd.read_csv('BFX-USTUSD-1d.csv', usecols=['timestamp', 'open', 'close', 'high', 'low', 'volume'])\n",
    "usdt_1h = pd.read_csv('BFX-USTUSD-1h.csv', usecols=['timestamp', 'open', 'close', 'high', 'low', 'volume'])\n",
    "usdt_15m = pd.read_csv('BFX-USTUSD-15m.csv', usecols=['timestamp', 'open', 'close', 'high', 'low', 'volume'])\n",
    "usdt_1m = pd.read_csv('BFX-USTUSD-1m.csv', usecols=['timestamp', 'open', 'close', 'high', 'low', 'volume'])\n",
    "\n",
    "usdc_1d = pd.read_csv('BNC-USDCUSDT-1d.csv', usecols=['timestamp', 'open', 'close', 'high', 'low', 'volume'])\n",
    "usdc_1h = pd.read_csv('BNC-USDCUSDT-1h.csv', usecols=['timestamp', 'open', 'close', 'high', 'low', 'volume'])\n",
    "usdc_15m = pd.read_csv('BNC-USDCUSDT-15m.csv', usecols=['timestamp', 'open', 'close', 'high', 'low', 'volume'])\n",
    "usdc_1m = pd.read_csv('BNC-USDCUSDT-1m.csv', usecols=['timestamp', 'open', 'close', 'high', 'low', 'volume'])\n",
    "\n",
    "busd_1d = pd.read_csv('BNC-BUSDUSDT-1d.csv', usecols=['timestamp', 'open', 'close', 'high', 'low', 'volume'])\n",
    "busd_1h = pd.read_csv('BNC-BUSDUSDT-1h.csv', usecols=['timestamp', 'open', 'close', 'high', 'low', 'volume'])\n",
    "busd_15m = pd.read_csv('BNC-BUSDUSDT-15m.csv', usecols=['timestamp', 'open', 'close', 'high', 'low', 'volume'])\n",
    "busd_1m = pd.read_csv('BNC-BUSDUSDT-1m.csv', usecols=['timestamp', 'open', 'close', 'high', 'low', 'volume'])\n",
    "\n",
    "dai_1d = pd.read_csv('BNC-USDTDAI-1d.csv', usecols=['timestamp', 'open', 'close', 'high', 'low', 'volume'])\n",
    "dai_1h = pd.read_csv('BNC-USDTDAI-1h.csv', usecols=['timestamp', 'open', 'close', 'high', 'low', 'volume'])\n",
    "dai_15m = pd.read_csv('BNC-USDTDAI-15m.csv', usecols=['timestamp', 'open', 'close', 'high', 'low', 'volume'])\n",
    "dai_1m = pd.read_csv('BNC-USDTDAI-1m.csv', usecols=['timestamp', 'open', 'close', 'high', 'low', 'volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "greek-seeker",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_and_merge(df1, df2, df3, df4, df5, tokenA, tokenB, tokenC, tokenD, tokenE, timeframe):\n",
    "    \n",
    "    #use only relevant columns\n",
    "    df1_copy = df1[['timestamp', 'close', 'volume']].copy()\n",
    "    # df2 is USDT\n",
    "    df2_copy = df2[['timestamp', 'close', 'volume']].copy()\n",
    "    df3_copy = df3[['timestamp', 'close', 'volume']].copy()\n",
    "    df4_copy = df4[['timestamp', 'close', 'volume']].copy()\n",
    "    df5_copy = df5[['timestamp', 'close', 'volume']].copy()\n",
    "    \n",
    "    # normalize Binance Stablecoins \n",
    "    stables = [[df3_copy, tokenC], [df4_copy, tokenD], [df5_copy, tokenE]]\n",
    "    for stable in stables:\n",
    "        temp_stable = df2_copy.merge(stable[0], how='left', on=['timestamp'])\n",
    "        temp_stable['close'] = temp_stable['close_y'] * temp_stable['close_x']\n",
    "        temp_stable['volume'] = temp_stable['volume_y']\n",
    "        stable[0] = temp_stable[['timestamp', 'close', 'volume']].copy()\n",
    "        \n",
    "    # Calculate log returns for all tokens + rename all columns\n",
    "    lst = [[df1_copy, tokenA], [df2_copy, tokenB], [df3_copy, tokenC], [df4_copy, tokenD], [df5_copy, tokenE]]\n",
    "    for pair in lst:\n",
    "        column_name = 'return_' + pair[1]\n",
    "        pair[0].columns = ['timestamp', 'close_' + pair[1], 'volume_' + pair[1]]\n",
    "        pair[0][column_name] = (pair[0]['close_' + pair[1]].pct_change())\n",
    "        pair[0][column_name + '_log'] = (np.log(1 + pair[0][column_name])) * 100\n",
    "        \n",
    "    # Make columns for every quantile relevant for BTC\n",
    "    df1_copy['Dq_10'] = df1_copy['return_BTC_log'].apply(lambda x: 1 if x < df1_copy['return_BTC_log'].quantile(.1) else 0)\n",
    "    df1_copy['Dq_05'] = df1_copy['return_BTC_log'].apply(lambda x: 1 if x < df1_copy['return_BTC_log'].quantile(.05) else 0)\n",
    "    df1_copy['Dq_01'] = df1_copy['return_BTC_log'].apply(lambda x: 1 if x < df1_copy['return_BTC_log'].quantile(.01) else 0)\n",
    "    \n",
    "    # Merge all dataframes\n",
    "    merged = df1_copy.copy()\n",
    "    lst2 = [df2_copy, df3_copy, df4_copy, df5_copy]\n",
    "    for df in lst2:\n",
    "        merged = merged.merge(df, how='left', on=['timestamp'])\n",
    "    \n",
    "    merged.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    est = smf.ols(formula='return_USDT_log ~  return_BTC_log * Dq_10 + return_BTC_log * Dq_05 + return_BTC_log * Dq_01', data=merged).fit(cov_type='HAC', cov_kwds={'maxlags':1})\n",
    "    est4 = smf.ols(formula='return_DAI_log ~  return_BTC_log * Dq_10 + return_BTC_log * Dq_05 + return_BTC_log * Dq_01', data=merged).fit(cov_type='HAC', cov_kwds={'maxlags':1})\n",
    "    est3 = smf.ols(formula='return_BUSD_log ~  return_BTC_log * Dq_10 + return_BTC_log * Dq_05 + return_BTC_log * Dq_01', data=merged).fit(cov_type='HAC', cov_kwds={'maxlags':1})\n",
    "    est2 = smf.ols(formula='return_USDC_log ~  return_BTC_log * Dq_10 + return_BTC_log * Dq_05 + return_BTC_log * Dq_01', data=merged).fit(cov_type='HAC', cov_kwds={'maxlags':1})\n",
    "\n",
    "    stargazer = Stargazer([est, est2, est3, est4])\n",
    "\n",
    "    stargazer.custom_columns(['USDT', 'USDC', 'BUSD', 'DAI'], [1, 1, 1, 1])\n",
    "    stargazer.show_model_numbers(False)\n",
    "    stargazer.title(f'Safe Haven Test: Regression results of the {timeframe} timeframe')\n",
    "        \n",
    "    return stargazer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "narrow-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15-minute timeframe\n",
    "transform_and_merge(btc_15m, usdt_15m, dai_15m, busd_15m, usdc_15m, \"BTC\",\"USDT\", \"DAI\", \"BUSD\", \"USDC\", \"15-minute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "scheduled-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-hour timeframe\n",
    "transform_and_merge(btc_1h, usdt_1h, dai_1h, busd_1h, usdc_1h, \"BTC\",\"USDT\", \"DAI\", \"BUSD\", \"USDC\", \"1-hour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily timeframe\n",
    "transform_and_merge(btc_1d, usdt_1d, dai_1d, busd_1d, usdc_1d, \"BTC\",\"USDT\", \"DAI\", \"BUSD\", \"USDC\", \"daily\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
